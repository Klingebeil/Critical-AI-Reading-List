# A Critical AI Reading List for Journalists
A critical reading list on AI technologies for journalists.

## Function

## Limitations and challenges of AI

**[A Berkeley View of Systems Challenges for AI](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2017/EECS-2017-159.html)** (December 15, 2017) Ion Stoica, Dawn Song, Raluca Ada Popa, David Pa erson, Michael W. Mahoney, Randy Katz, Anthony D. Joseph, Michael Jordan, Joseph M. Hellerstein, Joseph Gonzalez, Ken Goldberg, Ali Ghodsi, David Culler, Pieter Abbeel. Berkley EECS

**[Deep Learning: A Critical Appraisal](https://arxiv.org/pdf/1801.00631.pdf)** (December 18, 2017). Marcus, Gary. New York University

Gary Marcus' view on deep learning is more critical, than the Berkeley overview. He argues, that deep learning wont be enough to ever reach a general artificial intelligence. There are definite limits to the technique.

> Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.

A summary can be found in this Wired Article [Wise up, deep learning may never create a general purpose AI](http://www.wired.co.uk/article/deep-learning-automl-cloud-gary-marcus) (January 20, 2018) by Greg Williams.

## AI & Jobs

**[What can machine learning do? Workforce implications](http://science.sciencemag.org/content/358/6370/1530)** (December 22, 2017). Erik Brynjolfsson, Tom Mitchell. Science.

  A great article on the characteristics a task needs to have, to be automated by a machine learning system.
  
 > Although recent advances in the capabilities of ML systems are impressive, they are not equally suitable for all tasks. The cur- rent wave of successes draw particularly heavily on a paradigm known as supervised learning, typically using DNNs. They can be immensely powerful in domains that are well suited for such use. However, their competence is also dramatically narrower and more fragile than human decision-making, and there are many tasks for which this approach is completely ineffective



## Criticism

**[Situating Methods in the Magic of Big Data and Artificial Intelligence]**(https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3040201) (September 20, 2017), Elish, M. C. and Boyd, Danah. Communication Monographs

  Elish and Danah explore the myth around Big Data and AI as "magcial" technologies. The article is worth reading for an insight in the business of AI and Big Data, as well as a critical perspecitve on the real possibilities and challenges of both technologies. A shorter article is available on [Medium](https://points.datasociety.net/dont-call-ai-magic-142da16db408).
  
> The uncritical embrace of AI technologies has troubling implications for established forms of accountability, and for the protection of our most vulnerable populations. AI is increasingly being positioned as the answer to every question, in part because AI seems to promise not only efficiency and insight, but also neutrality and fairness — ideals that are often viewed as impossible to achieve through individual human or organizational decision-making processes. The fantasies and promises of AI often obscure the limitations of the field and the complicated trade-offs of technical work done under the rubric of “AI.”

**[Manufacturing an Artificial Intelligence Revolution]**(https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3078224) (November 27, 2017), Katz, Yarden. 

  Definitely one of the most critical views on AI I've read so far. I am not sure, if I would agree to every point Katz raises, but it‘s a perespective worth considering.

> I argue here that the "AI" label has been rebranded to promote a contested vision of world governance through big data. Major tech companies have played a key role in the rebranding, partly by hiring academics that work on big data (which has been effectively relabeled "AI") and helping to create the sense that super-human AI is imminent. However, I argue that the latest AI systems are premised on an old behaviorist view of intelligence that's far from encompassing human thought. In practice, the confusion around AI's capacities serves as a pretext for imposing more metrics upon human endeavors and advancing traditional neoliberal policies. The revived AI, like its predecessors, seeks intelligence with a "view from nowhere" (disregarding race, gender and class)---which can also be used to mask institutional power in visions of AI-based governance. Ultimately, AI's rebranding showcases how corporate interests can rapidly reconfigure academic fields. It also brings to light how a nebulous technical term (AI) may be exploited for political gain.
